## Evaluation Metrics

- **Precision**: The proportion of positive predictions that were correct.
- **Recall**: The proportion of true positives that were correctly identified by the model.
- **F1-Score**: Harmonic mean of precision/recall  
- **Confusion Matrix**
- **AUC-ROC**: A graphical representation of a model's ability to distinguish between two classes.

_For more details refer to Comparative_Analysis_of_Different_Formality_Detection_Approaches.pdf_
